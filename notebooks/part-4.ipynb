{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ac866250",
   "metadata": {},
   "source": [
    "# Part 4 — Machine Learning\n",
    "\n",
    "## Links\n",
    "- **Live updated app:** https://ind320-project-work-nonewthing.streamlit.app/\n",
    "- **Repo:** https://github.com/TaoM29/IND320-dashboard-basics\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd831b05",
   "metadata": {},
   "source": [
    "## AI Usage\n",
    "\n",
    "I Used an ChatGPT 5 as a coding and troubleshooting partner. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1e8b3c",
   "metadata": {},
   "source": [
    "## Work Log\n",
    "\n",
    "### Spark vs. Cassandra Driver\n",
    "- I followed the assignment’s data scope:\n",
    "  - **Production**: PRODUCTION_PER_GROUP_MBA_HOUR for **2022–2024** (all price areas).\n",
    "  - **Consumption**: CONSUMPTION_PER_GROUP_MBA_HOUR for **2021–2024** (all price areas).\n",
    "- API fetching mirrors my Part 2 approach (monthly paging), but expanded across years and areas.\n",
    "- **Spark+Cassandra Connector**: I attempted multiple configurations (3.5.1 connector, assembly JAR, shaded driver, Java 11) and verified Docker Cassandra 5.0.6 running on localhost:9042.\n",
    "  - Despite successful Spark sessions, the JVM side intermittently failed to load the DataStax Java driver (`CqlSession`) and/or could not resolve the `system` keyspace from the connector in this environment.\n",
    "  - After repeated trials (assembly JAR, non-assembly + explicit driver JARs, log-level tweaks), Spark writes remained unstable locally.\n",
    "- Per the course installation page’s fallback advice and teacher guidance, I completed the database writes with the **official Python Cassandra driver** (idempotent bulk upserts), which is valid and reliable for this dataset size.\n",
    "- MongoDB writes are done via **bulk upserts** with **unique compound indexes**, so the notebook can be re-run safely without duplicating rows.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "118d89c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports, paths, env\n",
    "import os, sys\n",
    "from pathlib import Path\n",
    "from datetime import datetime, timezone\n",
    "import os, requests, pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "import itertools\n",
    "from pyspark.sql import functions as F\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c78011",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "BASE_V0 = \"https://api.elhub.no/energy-data/v0\"\n",
    "ELHUB_API_TOKEN = os.getenv(\"ELHUB_API_TOKEN\")  \n",
    "PRICE_AREAS = [\"NO1\",\"NO2\",\"NO3\",\"NO4\",\"NO5\"]\n",
    "\n",
    "\n",
    "# Common headers for JSON:API\n",
    "def headers_jsonapi():\n",
    "    h = {\"Accept\": \"application/vnd.api+json\"}\n",
    "    if ELHUB_API_TOKEN:\n",
    "        h[\"Authorization\"] = f\"Bearer {ELHUB_API_TOKEN}\"\n",
    "    return h\n",
    "\n",
    "# ISO 8601 UTC offset formatting\n",
    "def iso_utc_offset(dt: datetime) -> str:\n",
    "    if dt.tzinfo is None:\n",
    "        dt = dt.replace(tzinfo=timezone.utc)\n",
    "    dt = dt.astimezone(timezone.utc)\n",
    "    off = dt.strftime(\"%z\")\n",
    "    off = off[:-2] + \":\" + off[-2:]\n",
    "    return dt.strftime(\"%Y-%m-%dT%H:%M:%S\") + off\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f33f7b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Production groups: ['solar', 'hydro', 'wind', 'thermal', 'nuclear', 'other']\n",
      "Consumption groups: ['household', 'cabin', 'primary', 'secondary', 'tertiary', 'industry', 'private', 'business']\n"
     ]
    }
   ],
   "source": [
    "# Groups (ids)\n",
    "def list_groups(kind=\"production\"):\n",
    "    url = f\"{BASE_V0}/{kind}-groups\"\n",
    "    r = requests.get(url, headers=headers_jsonapi(), timeout=30)\n",
    "    r.raise_for_status()\n",
    "    rows = []\n",
    "    for item in r.json().get(\"data\", []):\n",
    "        attrs = item.get(\"attributes\", {}) or {}\n",
    "        rows.append({\"id\": item.get(\"id\"), \"name\": attrs.get(\"name\")})\n",
    "    df = pd.DataFrame(rows)\n",
    "  \n",
    "    ids = [g for g in df[\"id\"].tolist() if g != \"*\"]\n",
    "    return ids, df\n",
    "\n",
    "prod_group_ids, production_groups_df = list_groups(\"production\")\n",
    "cons_group_ids, consumption_groups_df = list_groups(\"consumption\")\n",
    "\n",
    "print(\"Production groups:\", prod_group_ids)\n",
    "print(\"Consumption groups:\", cons_group_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3775691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generic monthly fetch\n",
    "def fetch_month_generic(\n",
    "    price_area: str,\n",
    "    group_id: str,\n",
    "    year: int,\n",
    "    month: int,\n",
    "    dataset: str,\n",
    "    group_param_name: str,\n",
    "    inner_key: str,\n",
    "    group_col_out: str,\n",
    "    verbose: bool = False,\n",
    ") -> pd.DataFrame:\n",
    "    start = datetime(year, month, 1, tzinfo=timezone.utc)\n",
    "    end   = datetime(year + (month==12), (month % 12) + 1, 1, tzinfo=timezone.utc)\n",
    "\n",
    "    params = {\n",
    "        \"dataset\": dataset,\n",
    "        \"priceArea\": price_area,\n",
    "        group_param_name: group_id,\n",
    "        \"startDate\": iso_utc_offset(start),\n",
    "        \"endDate\":   iso_utc_offset(end),\n",
    "        \"pageSize\":  10000,\n",
    "    }\n",
    "\n",
    "    url = f\"{BASE_V0}/price-areas\"\n",
    "    r = requests.get(url, headers=headers_jsonapi(), params=params, timeout=90)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"HTTP\", r.status_code, \"|\", r.headers.get(\"Content-Type\"))\n",
    "        print(\"URL:\", r.url)\n",
    "\n",
    "    if r.status_code != 200:\n",
    "        if verbose: print(\"Body preview:\", r.text[:400])\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    data = r.json().get(\"data\", [])\n",
    "    if not data:\n",
    "        return pd.DataFrame(columns=[\"priceArea\", group_col_out, \"startTime\", \"quantityKwh\"])\n",
    "\n",
    "    rows = []\n",
    "    for rec in data:\n",
    "        attrs = rec.get(\"attributes\", {}) or {}\n",
    "        area  = attrs.get(\"name\") or rec.get(\"id\") or price_area\n",
    "        inner = attrs.get(inner_key, []) or []\n",
    "        for item in inner:\n",
    "            rows.append({\n",
    "                \"priceArea\": area,\n",
    "                group_col_out: item.get(group_col_out),\n",
    "                \"startTime\": item.get(\"startTime\"),\n",
    "                \"quantityKwh\": item.get(\"quantityKwh\")\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(rows)\n",
    "    if df.empty:\n",
    "        return df\n",
    "\n",
    "    df[\"startTime\"]   = pd.to_datetime(df[\"startTime\"], utc=True, errors=\"coerce\")\n",
    "    df[\"quantityKwh\"] = pd.to_numeric(df[\"quantityKwh\"], errors=\"coerce\")\n",
    "    df = df.dropna(subset=[\"startTime\",\"quantityKwh\"]).reset_index(drop=True)\n",
    "    return df\n",
    "\n",
    "\n",
    "# Thin wrappers (so our code stays readable)\n",
    "def fetch_month_prod(area, group_id, year, month, verbose=False):\n",
    "    return fetch_month_generic(\n",
    "        area, group_id, year, month,\n",
    "        dataset=\"PRODUCTION_PER_GROUP_MBA_HOUR\",\n",
    "        group_param_name=\"productionGroup\",\n",
    "        inner_key=\"productionPerGroupMbaHour\",\n",
    "        group_col_out=\"productionGroup\",\n",
    "        verbose=verbose,\n",
    "    )\n",
    "\n",
    "def fetch_month_cons(area, group_id, year, month, verbose=False):\n",
    "    return fetch_month_generic(\n",
    "        area, group_id, year, month,\n",
    "        dataset=\"CONSUMPTION_PER_GROUP_MBA_HOUR\",\n",
    "        group_param_name=\"consumptionGroup\",\n",
    "        inner_key=\"consumptionPerGroupMbaHour\",\n",
    "        group_col_out=\"consumptionGroup\",\n",
    "        verbose=verbose,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "76132b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Planned requests (prod): 1080 months = 5 areas × 6 groups × 3 years × 12 months\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fa60e161517444ba963b705e9829408b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Production (2022–2024) months:   0%|          | 0/1080 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== PRODUCTION 2022–2024 ===\n",
      "Requests run: 1080 | Non-empty months: 900 | Rows: 657,600\n",
      "Span: 2021-12-31 23:00:00+00:00 → 2024-12-31 22:00:00+00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceArea</th>\n",
       "      <th>productionGroup</th>\n",
       "      <th>startTime</th>\n",
       "      <th>quantityKwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO1</td>\n",
       "      <td>solar</td>\n",
       "      <td>2021-12-31 23:00:00+00:00</td>\n",
       "      <td>6.448</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NO1</td>\n",
       "      <td>solar</td>\n",
       "      <td>2022-01-01 00:00:00+00:00</td>\n",
       "      <td>6.062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO1</td>\n",
       "      <td>solar</td>\n",
       "      <td>2022-01-01 01:00:00+00:00</td>\n",
       "      <td>4.697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO1</td>\n",
       "      <td>solar</td>\n",
       "      <td>2022-01-01 02:00:00+00:00</td>\n",
       "      <td>10.907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NO1</td>\n",
       "      <td>solar</td>\n",
       "      <td>2022-01-01 03:00:00+00:00</td>\n",
       "      <td>5.975</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  priceArea productionGroup                 startTime  quantityKwh\n",
       "0       NO1           solar 2021-12-31 23:00:00+00:00        6.448\n",
       "1       NO1           solar 2022-01-01 00:00:00+00:00        6.062\n",
       "2       NO1           solar 2022-01-01 01:00:00+00:00        4.697\n",
       "3       NO1           solar 2022-01-01 02:00:00+00:00       10.907\n",
       "4       NO1           solar 2022-01-01 03:00:00+00:00        5.975"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch production data for 2022–2024\n",
    "YEARS_PROD = [2022, 2023, 2024]\n",
    "\n",
    "total_months = len(PRICE_AREAS) * len(prod_group_ids) * len(YEARS_PROD) * 12\n",
    "print(f\"Planned requests (prod): {total_months} months \"\n",
    "      f\"= {len(PRICE_AREAS)} areas × {len(prod_group_ids)} groups × {len(YEARS_PROD)} years × 12 months\")\n",
    "\n",
    "parts, runs, non_empty, row_count = [], 0, 0, 0\n",
    "pbar = tqdm(total=total_months, desc=\"Production (2022–2024) months\", leave=True)\n",
    "\n",
    "for area in PRICE_AREAS:\n",
    "    for g in prod_group_ids:\n",
    "        for y, m in itertools.product(YEARS_PROD, range(1, 13)):\n",
    "            df_m = fetch_month_prod(area, g, y, m)\n",
    "            runs += 1\n",
    "            if not df_m.empty:\n",
    "                parts.append(df_m)\n",
    "                non_empty += 1\n",
    "                row_count += len(df_m)\n",
    "            # update progress every month\n",
    "            pbar.set_postfix_str(f\"rows_so_far={row_count:,}\")\n",
    "            pbar.update(1)\n",
    "\n",
    "pbar.close()\n",
    "\n",
    "prod_2224 = (pd.concat(parts, ignore_index=True)\n",
    "             if parts else pd.DataFrame(columns=[\"priceArea\",\"productionGroup\",\"startTime\",\"quantityKwh\"]))\n",
    "prod_2224 = prod_2224.drop_duplicates(subset=[\"priceArea\",\"productionGroup\",\"startTime\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== PRODUCTION 2022–2024 ===\")\n",
    "print(f\"Requests run: {runs} | Non-empty months: {non_empty} | Rows: {len(prod_2224):,}\")\n",
    "print(\"Span:\", prod_2224[\"startTime\"].min() if not prod_2224.empty else None,\n",
    "      \"→\",  prod_2224[\"startTime\"].max() if not prod_2224.empty else None)\n",
    "display(prod_2224.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e83b4980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Planned requests (cons): 1920 months = 5 areas × 8 groups × 4 years × 12 months\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5d1db6e494e4c93ae775afd0715bfa3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Consumption (2021–2024) months:   0%|          | 0/1920 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== CONSUMPTION 2021–2024 ===\n",
      "Requests run: 1920 | Non-empty months: 1200 | Rows: 876,600\n",
      "Span: 2020-12-31 23:00:00+00:00 → 2024-12-31 22:00:00+00:00\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>priceArea</th>\n",
       "      <th>consumptionGroup</th>\n",
       "      <th>startTime</th>\n",
       "      <th>quantityKwh</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NO1</td>\n",
       "      <td>household</td>\n",
       "      <td>2020-12-31 23:00:00+00:00</td>\n",
       "      <td>2366888.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NO1</td>\n",
       "      <td>household</td>\n",
       "      <td>2021-01-01 00:00:00+00:00</td>\n",
       "      <td>2325218.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NO1</td>\n",
       "      <td>household</td>\n",
       "      <td>2021-01-01 01:00:00+00:00</td>\n",
       "      <td>2273791.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NO1</td>\n",
       "      <td>household</td>\n",
       "      <td>2021-01-01 02:00:00+00:00</td>\n",
       "      <td>2221311.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NO1</td>\n",
       "      <td>household</td>\n",
       "      <td>2021-01-01 03:00:00+00:00</td>\n",
       "      <td>2188174.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  priceArea consumptionGroup                 startTime  quantityKwh\n",
       "0       NO1        household 2020-12-31 23:00:00+00:00    2366888.8\n",
       "1       NO1        household 2021-01-01 00:00:00+00:00    2325218.2\n",
       "2       NO1        household 2021-01-01 01:00:00+00:00    2273791.2\n",
       "3       NO1        household 2021-01-01 02:00:00+00:00    2221311.8\n",
       "4       NO1        household 2021-01-01 03:00:00+00:00    2188174.2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fetch consumption data for 2021–2024\n",
    "YEARS_CONS = [2021, 2022, 2023, 2024]\n",
    "\n",
    "total_months_c = len(PRICE_AREAS) * len(cons_group_ids) * len(YEARS_CONS) * 12\n",
    "print(f\"\\nPlanned requests (cons): {total_months_c} months \"\n",
    "      f\"= {len(PRICE_AREAS)} areas × {len(cons_group_ids)} groups × {len(YEARS_CONS)} years × 12 months\")\n",
    "\n",
    "parts_c, runs_c, non_empty_c, row_count_c = [], 0, 0, 0\n",
    "pbar_c = tqdm(total=total_months_c, desc=\"Consumption (2021–2024) months\", leave=True)\n",
    "\n",
    "for area in PRICE_AREAS:\n",
    "    for g in cons_group_ids:\n",
    "        for y, m in itertools.product(YEARS_CONS, range(1, 13)):\n",
    "            df_m = fetch_month_cons(area, g, y, m)\n",
    "            runs_c += 1\n",
    "            if not df_m.empty:\n",
    "                parts_c.append(df_m)\n",
    "                non_empty_c += 1\n",
    "                row_count_c += len(df_m)\n",
    "            pbar_c.set_postfix_str(f\"rows_so_far={row_count_c:,}\")\n",
    "            pbar_c.update(1)\n",
    "\n",
    "pbar_c.close()\n",
    "\n",
    "cons_2124 = (pd.concat(parts_c, ignore_index=True)\n",
    "             if parts_c else pd.DataFrame(columns=[\"priceArea\",\"consumptionGroup\",\"startTime\",\"quantityKwh\"]))\n",
    "cons_2124 = cons_2124.drop_duplicates(subset=[\"priceArea\",\"consumptionGroup\",\"startTime\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== CONSUMPTION 2021–2024 ===\")\n",
    "print(f\"Requests run: {runs_c} | Non-empty months: {non_empty_c} | Rows: {len(cons_2124):,}\")\n",
    "print(\"Span:\", cons_2124[\"startTime\"].min() if not cons_2124.empty else None,\n",
    "      \"→\",  cons_2124[\"startTime\"].max() if not cons_2124.empty else None)\n",
    "display(cons_2124.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f55d517",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tables in ind320: ['consumption_mba_hour', 'production_mba_hour']\n"
     ]
    }
   ],
   "source": [
    "# [CASSANDRA] Connect + ensure tables \n",
    "from cassandra.cluster import Cluster\n",
    "from cassandra.auth import PlainTextAuthProvider\n",
    "\n",
    "CASS_HOST = \"127.0.0.1\"\n",
    "CASS_PORT = 9042\n",
    "KEYSPACE  = \"ind320\"\n",
    "\n",
    "auth_provider = None  \n",
    "\n",
    "cluster = Cluster([CASS_HOST], port=CASS_PORT, auth_provider=auth_provider)\n",
    "session = cluster.connect()\n",
    "\n",
    "# Create keyspace/tables idempotently\n",
    "session.execute(\"\"\"\n",
    "CREATE KEYSPACE IF NOT EXISTS ind320\n",
    "  WITH replication = {'class': 'SimpleStrategy', 'replication_factor': 1}\n",
    "\"\"\")\n",
    "\n",
    "session.set_keyspace(KEYSPACE)\n",
    "\n",
    "session.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS production_mba_hour (\n",
    "  price_area text,\n",
    "  production_group text,\n",
    "  year int,\n",
    "  start_time timestamp,\n",
    "  quantity_kwh double,\n",
    "  PRIMARY KEY ((price_area, production_group, year), start_time)\n",
    ") WITH CLUSTERING ORDER BY (start_time ASC)\n",
    "\"\"\")\n",
    "\n",
    "session.execute(\"\"\"\n",
    "CREATE TABLE IF NOT EXISTS consumption_mba_hour (\n",
    "  price_area text,\n",
    "  consumption_group text,\n",
    "  year int,\n",
    "  start_time timestamp,\n",
    "  quantity_kwh double,\n",
    "  PRIMARY KEY ((price_area, consumption_group, year), start_time)\n",
    ") WITH CLUSTERING ORDER BY (start_time ASC)\n",
    "\"\"\")\n",
    "\n",
    "# Quick check\n",
    "rows = session.execute(\"SELECT table_name FROM system_schema.tables WHERE keyspace_name=%s\", [KEYSPACE])\n",
    "print(\"Tables in ind320:\", sorted([r.table_name for r in rows]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865e3a13",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PROD rows: 657600 range: 2021-12-31 23:00:00 → 2024-12-31 22:00:00\n",
      "CONS rows: 876600 range: 2020-12-31 23:00:00 → 2024-12-31 22:00:00\n"
     ]
    }
   ],
   "source": [
    "# [NORMALIZE] prod_2224 and cons_2124 to canonical columns \n",
    "import pandas as pd\n",
    "from pandas.errors import ParserError\n",
    "\n",
    "def to_cassandra_prod(pdf: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = pdf.copy()\n",
    "    df[\"price_area\"]       = df[\"priceArea\"]\n",
    "    df[\"production_group\"] = df[\"productionGroup\"]\n",
    "    df[\"start_time\"]       = pd.to_datetime(df[\"startTime\"], utc=True, errors=\"coerce\").dt.tz_localize(None)\n",
    "    df[\"quantity_kwh\"]     = pd.to_numeric(df[\"quantityKwh\"], errors=\"coerce\")\n",
    "    df = df[[\"price_area\",\"production_group\",\"start_time\",\"quantity_kwh\"]].dropna()\n",
    "    df[\"year\"]             = df[\"start_time\"].dt.year.astype(int)\n",
    "    return df\n",
    "\n",
    "def to_cassandra_cons(pdf: pd.DataFrame) -> pd.DataFrame:\n",
    "    df = pdf.copy()\n",
    "    df[\"price_area\"]        = df[\"priceArea\"]\n",
    "    df[\"consumption_group\"] = df[\"consumptionGroup\"]\n",
    "    df[\"start_time\"]        = pd.to_datetime(df[\"startTime\"], utc=True, errors=\"coerce\").dt.tz_localize(None)\n",
    "    df[\"quantity_kwh\"]      = pd.to_numeric(df[\"quantityKwh\"], errors=\"coerce\")\n",
    "    df = df[[\"price_area\",\"consumption_group\",\"start_time\",\"quantity_kwh\"]].dropna()\n",
    "    df[\"year\"]              = df[\"start_time\"].dt.year.astype(int)\n",
    "    return df\n",
    "\n",
    "prod_cas = to_cassandra_prod(prod_2224)\n",
    "cons_cas = to_cassandra_cons(cons_2124)\n",
    "\n",
    "print(\"PROD rows:\", len(prod_cas), \"range:\", prod_cas[\"start_time\"].min(), \"→\", prod_cas[\"start_time\"].max())\n",
    "print(\"CONS rows:\", len(cons_cas), \"range:\", cons_cas[\"start_time\"].min(), \"→\", cons_cas[\"start_time\"].max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "df6fc741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cassandra upserts completed.\n"
     ]
    }
   ],
   "source": [
    "# QUIET Cassandra bulk upsert (minimal output, safe to rerun)\n",
    "from cassandra.concurrent import execute_concurrent_with_args\n",
    "import pandas as pd\n",
    "import logging\n",
    "\n",
    "# Silence noisy Python-side Cassandra logs for this cell\n",
    "logging.getLogger(\"cassandra\").setLevel(logging.ERROR)\n",
    "\n",
    "# Ensure keyspace is active (no-op if already set)\n",
    "try:\n",
    "    session.set_keyspace(\"ind320\")\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# Prepared statements (idempotent to re-prepare)\n",
    "prep_prod = session.prepare(\"\"\"\n",
    "INSERT INTO ind320.production_mba_hour\n",
    "(price_area, production_group, year, start_time, quantity_kwh)\n",
    "VALUES (?, ?, ?, ?, ?)\n",
    "\"\"\")\n",
    "prep_cons = session.prepare(\"\"\"\n",
    "INSERT INTO ind320.consumption_mba_hour\n",
    "(price_area, consumption_group, year, start_time, quantity_kwh)\n",
    "VALUES (?, ?, ?, ?, ?)\n",
    "\"\"\")\n",
    "\n",
    "def _to_native_args(df, cols):\n",
    "    out = []\n",
    "    for pa, grp, yr, ts, qty in df[cols].itertuples(index=False, name=None):\n",
    "        ts = pd.to_datetime(ts, utc=True).tz_localize(None).to_pydatetime()  # naive UTC\n",
    "        out.append((str(pa), str(grp), int(yr), ts, float(qty)))\n",
    "    return out\n",
    "\n",
    "prod_args = _to_native_args(\n",
    "    prod_cas, [\"price_area\",\"production_group\",\"year\",\"start_time\",\"quantity_kwh\"]\n",
    ")\n",
    "cons_args = _to_native_args(\n",
    "    cons_cas, [\"price_area\",\"consumption_group\",\"year\",\"start_time\",\"quantity_kwh\"]\n",
    ")\n",
    "\n",
    "# Execute quietly (no per-row logging, no COUNT(*))\n",
    "_ = execute_concurrent_with_args(session, prep_prod, prod_args, concurrency=256, raise_on_first_error=False)\n",
    "_ = execute_concurrent_with_args(session, prep_cons, cons_args, concurrency=256, raise_on_first_error=False)\n",
    "\n",
    "print(\"✅ Cassandra upserts completed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7fbc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mongo PRODUCTION upserts: 657575  |  updates: 0  |  total docs now: 657575\n",
      "Mongo CONSUMPTION upserts: 876600  |  updates: 0  |  total docs now: 876600\n"
     ]
    }
   ],
   "source": [
    "# [MONGODB] bulk upsert to two collections \n",
    "from pymongo import MongoClient, UpdateOne\n",
    "import os\n",
    "\n",
    "MONGO_URI = \"mongodb+srv://Taofik29:bcR3sF4Cs48ucLSx@cluster007.kkmkf1u.mongodb.net/?retryWrites=true&w=majority&appName=Cluster007&authSource=admin\"\n",
    "MDB_NAME  = \"ind320\"\n",
    "COL_PROD  = \"elhub_production_mba_hour\"\n",
    "COL_CONS  = \"elhub_consumption_mba_hour\"\n",
    "    \n",
    "client = MongoClient(MONGO_URI)\n",
    "mdb = client[MDB_NAME]\n",
    "\n",
    "prod_col = mdb[COL_PROD]\n",
    "cons_col = mdb[COL_CONS]\n",
    "\n",
    "# indexes (unique compound ensures idempotence)\n",
    "prod_col.create_index(\n",
    "    [(\"price_area\",1), (\"production_group\",1), (\"start_time\",1)],\n",
    "    unique=True, name=\"uniq_prod_area_group_time\"\n",
    ")\n",
    "cons_col.create_index(\n",
    "    [(\"price_area\",1), (\"consumption_group\",1), (\"start_time\",1)],\n",
    "    unique=True, name=\"uniq_cons_area_group_time\"\n",
    ")\n",
    "\n",
    "def upsert_df(df, col, key_fields):\n",
    "    ops = []\n",
    "    for rec in df.to_dict(orient=\"records\"):\n",
    "        key = {k: rec[k] for k in key_fields}\n",
    "        ops.append(UpdateOne(key, {\"$set\": rec}, upsert=True))\n",
    "    if not ops:\n",
    "        return (0,0)\n",
    "    res = col.bulk_write(ops, ordered=False)\n",
    "    return (res.upserted_count or 0, res.modified_count or 0)\n",
    "\n",
    "\n",
    "# PRODUCTION: only years 2022–2024 (append to our existing 2021 in Mongo)\n",
    "prod_mongo = prod_cas[prod_cas[\"year\"].between(2022, 2024)]\n",
    "u, m = upsert_df(prod_mongo, prod_col, [\"price_area\",\"production_group\",\"start_time\"])\n",
    "print(f\"Mongo PRODUCTION upserts: {u}  |  updates: {m}  |  total docs now: {prod_col.estimated_document_count()}\")\n",
    "\n",
    "# CONSUMPTION: 2021–2024 full load\n",
    "u, m = upsert_df(cons_cas, cons_col, [\"price_area\",\"consumption_group\",\"start_time\"])\n",
    "print(f\"Mongo CONSUMPTION upserts: {u}  |  updates: {m}  |  total docs now: {cons_col.estimated_document_count()}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "IND320env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
